{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33496281",
   "metadata": {},
   "source": [
    "# CureD: EDA measurement details\n",
    "This notebook aims to clean the data corresponding to measurements details of Karunya database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8efe3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from bokeh import core, io, palettes, models\n",
    "from bokeh.plotting import output_file, figure, show\n",
    "from bokeh.models import LinearAxis, Range1d\n",
    "\n",
    "from diabwellness.utils.plot_utils import display_factorial_planes\n",
    "\n",
    "# Change jupyter notebook to full width for extra visualization space\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 50000)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919e80cf",
   "metadata": {},
   "source": [
    "## \n",
    "## \n",
    "## Measurement Details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bf6ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = [\n",
    "    \"ID\",\n",
    "    \"APPOINT_ID\",\n",
    "    \"BMI\",\n",
    "    \"BP\",\n",
    "    \"COMPLAINTS\",\n",
    "    \"CREATED_BY\",\n",
    "    \"CREATED_DATE\",\n",
    "    \"DIAGNOSIS\",\n",
    "    \"HEIGHT\",\n",
    "    \"LOCATION_ID\",\n",
    "    \"NFID\",\n",
    "    \"STATUS\",\n",
    "    \"TEMPERATURE\",\n",
    "    \"UPDATED_BY\",\n",
    "    \"UPDATED_DATE\",\n",
    "    \"WC\",\n",
    "    \"WEIGHT\",\n",
    "    \"PATIENT_TYPE\",\n",
    "    \"A1C\",\n",
    "    \"DIA_BP\",\n",
    "    \"DURATION_TT\",\n",
    "    \"FS\",\n",
    "    \"NOTES\",\n",
    "    \"PP\",\n",
    "    \"PULSE\",\n",
    "    \"REVIEW_DATYS\",\n",
    "    \"ADMISSION_REQUIRED\",\n",
    "    \"REVIEW_DATE\",\n",
    "    \"LAB_FOR_NEXT_VISIT\",\n",
    "]\n",
    "meas_df = pd.read_csv(\n",
    "    \"../database/measurement_details.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    names=colnames,\n",
    "    header=None,\n",
    "    parse_dates=[\"CREATED_DATE\", \"UPDATED_DATE\"],\n",
    ")\n",
    "meas_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c54d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adfbe18",
   "metadata": {},
   "source": [
    "### Removing the NFID Nans as nothing can be done in that case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130ac927",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23dc9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_dfc = meas_df.dropna(subset=[\"NFID\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349f9db4",
   "metadata": {},
   "source": [
    "### Relevant columns:\n",
    "Relevant columns seem to be: \"APPOINT_ID\", \"NFID\", \"HEIGHT\", \"WEIGHT\", \"BMI\", \"BP\", \"DIA_BP\", \"DIAGNOSIS\", \"FS\", \"PP\", \"PULSE\", \"A1C\", \"PATIENT_TYPE\" \n",
    "\n",
    "We can perhaps do a prediction for diagnosis based on the given measurements here? Validity and pureness of Diagnosis? Common non-null values in all measurements? Group patients according to their measurements (unsupervised learning)\n",
    "\n",
    "Total number of records are  201766."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc564f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_dfc1 = meas_dfc[\n",
    "    [\n",
    "        \"APPOINT_ID\",\n",
    "        \"NFID\",\n",
    "        \"CREATED_DATE\",\n",
    "        \"HEIGHT\",\n",
    "        \"WEIGHT\",\n",
    "        \"BMI\",\n",
    "        \"BP\",\n",
    "        \"DIA_BP\",\n",
    "        \"FS\",\n",
    "        \"PP\",\n",
    "        \"PULSE\",\n",
    "        \"A1C\",\n",
    "        \"COMPLAINTS\",\n",
    "        \"PATIENT_TYPE\",\n",
    "        \"DIAGNOSIS\",\n",
    "        \"NOTES\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffff8aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_dfc1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ed4833",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_dfc1.PATIENT_TYPE.value_counts().head(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e8bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond1 = meas_dfc1[\"COMPLAINTS\"].str.contains(\"nan\", na=False, case=False)\n",
    "cond2 = meas_dfc1[\"PATIENT_TYPE\"].str.contains(\"nan\", na=False, case=False)\n",
    "cond3 = meas_dfc1[\"DIAGNOSIS\"].str.contains(\"nan\", na=False, case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72b0024",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_dfc1[cond1 & cond2 & cond3].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a795910",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_dfc1.loc[meas_dfc1[\"PATIENT_TYPE\"].str.contains(\"dm\", na=False, case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067d0e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_dfc1.loc[meas_dfc1[\"NOTES\"].str.contains(\"since\", na=False, case=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205f3fec",
   "metadata": {},
   "source": [
    "## \n",
    "## Takeaways:\n",
    "1. APPOINT_ID: 116k entries are 0; in measurements analysis can be done without APPOINT ID; some appoint ID repeated -> actually the same entry repeated, so drop duplicates!\n",
    "   Take Created Date as input to link and create artificial Appoint ID for 0 IDs.\n",
    "\n",
    "2. NFID: Very clean; nothing to change\n",
    "\n",
    "3. COMPLAINTS: The nil cases include some descriptions as well sometimes; and nil itself is valuable! \n",
    "   Perhaps fillna with \"nil\"? Okay\n",
    "   there are some \"Nan\" strings as well; okay\n",
    "   also this is where COMPLAINTS, PATIETNT_TYPE and DIAGNOSIS are all \"Nan\" (6235 entries). What do we do about them?\n",
    "\n",
    "4. PATIENT_TYPE: 14k Nan values; 6236 \"Nan\" strings; outliers can be processed to convert into good values; get help from doctor; \n",
    "   relevant entries: DM, NON DM, THY, HT, NON MS, IDDM, InflDisorder \n",
    "   Impute same patient type for a patient; still Nan: impute values from Complaints clues;\n",
    "   \"30\", \"15\": replace with DM\n",
    "    NON DM: Allergy, Anemia, Hlip, Hyperlipidemia\n",
    "    GDM: DM\n",
    "    CKD: based on diagnosis\n",
    "\n",
    "5. DIAGNOSIS: Check Nan values, is there something that we can do about this? Ask doctor; perhaps intented values?\n",
    "\n",
    "6. HEIGHT: 2887 entries are 0; some outliers; zeros can be filled by the mean/mode for the same patient\n",
    "\n",
    "7. WEIGHT: 2384 entries are 0; some outliers; zeros can be filled by mean/ mode for the same patient (this actually can be problematic, b/c patients can increase their weights); interpolation between values?\n",
    "\n",
    "8. BMI: recompute this entirely based on height and weight\n",
    "\n",
    "9. A1C: 57.5k entries are 0; could be because of infrequent recording; some text fields, so convert to numeric and coerce; some outliers; \n",
    "   infrequent information recording; like a reel; 3-4 months once recorded.\n",
    "   range = (4, 24) double digits maybe missing a decimal point!\n",
    "\n",
    "10. BP: 10.7k records are 0; some outliers and texts; recorded once in three months\n",
    "    range = (40, 200)\n",
    "\n",
    "11. DIA_BP: 9.9k entries are 0; some outliers; recorded once in three months\n",
    "    range = (40, 160)\n",
    "\n",
    "12. FS: 40k entries are 0; some outliers\n",
    "    range = (15, 1000)\n",
    "\n",
    "13. PP: 25.1k entries are 0; some outliers\n",
    "    range = (30, 1000)\n",
    "\n",
    "14. PULSE: 9316 entires are 0; some outliers and texts\n",
    "    range = (40, 160)\n",
    "    \n",
    "    Interpolation with available values\n",
    "    Take mean and std for PP and FS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4424e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_dfc2 = meas_dfc1.drop_duplicates(subset=[\"APPOINT_ID\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564054b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all number based cells to numeric and coerce errors to accumulate the NaNs\n",
    "numeric_cols = [\n",
    "    \"APPOINT_ID\",\n",
    "    \"NFID\",\n",
    "    \"HEIGHT\",\n",
    "    \"WEIGHT\",\n",
    "    \"BMI\",\n",
    "    \"BP\",\n",
    "    \"DIA_BP\",\n",
    "    \"FS\",\n",
    "    \"PP\",\n",
    "    \"PULSE\",\n",
    "    \"A1C\",\n",
    "]\n",
    "\n",
    "meas_dfc3 = pd.concat(\n",
    "    [\n",
    "        meas_dfc2.loc[:, numeric_cols].apply(pd.to_numeric, errors=\"coerce\"),\n",
    "        meas_dfc2.loc[:, meas_dfc2.columns.difference(numeric_cols)],\n",
    "    ],\n",
    "    axis=1,\n",
    ").reset_index(drop=True)\n",
    "\n",
    "meas_dfc3.NFID = meas_dfc3.NFID.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de52e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nan strings to Nan in Patient type:\n",
    "meas_dfc3[\"PATIENT_TYPE\"] = meas_dfc3[\"PATIENT_TYPE\"].replace(\"Nan\", np.nan)\n",
    "\n",
    "# replace 0 with Nan for every column except APPOINT_ID:\n",
    "meas_dfc3.loc[:, meas_dfc3.columns != \"APPOINT_ID\"] = meas_dfc3.loc[\n",
    "    :, meas_dfc3.columns != \"APPOINT_ID\"\n",
    "].replace(0, np.nan)\n",
    "meas_dfc3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf34ffb",
   "metadata": {},
   "source": [
    "## \n",
    "## \n",
    "## Outlier removal, interpolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f141ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove textual columns for better handling:\n",
    "meas_dfc4 = meas_dfc3.drop(columns=[\"COMPLAINTS\", \"DIAGNOSIS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d021d1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers removal:\n",
    "# https://stackoverflow.com/questions/35827863/remove-outliers-in-pandas-dataframe-using-percentiles\n",
    "\n",
    "outlier_cols = [\"HEIGHT\", \"WEIGHT\", \"BMI\", \"BP\", \"DIA_BP\", \"FS\", \"PP\", \"PULSE\", \"A1C\"]\n",
    "\n",
    "filt_df = meas_dfc4[outlier_cols]\n",
    "low = 0.01\n",
    "high = 0.99\n",
    "quant_df = filt_df.quantile([low, high])\n",
    "quant_df.head()\n",
    "# do you think you can go below these values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8250cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_df = filt_df.apply(\n",
    "    lambda x: x[(x > quant_df.loc[low, x.name]) & (x < quant_df.loc[high, x.name])],\n",
    "    axis=0,\n",
    ")\n",
    "filt_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5526e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_dfc4[outlier_cols] = filt_df\n",
    "meas_dfc4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7513a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_dfc4.isna().sum()\n",
    "# many new Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fb085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a cleaned version of the data\n",
    "meas_dfc4.to_csv(\"../database/cleaned_measurement_details.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d468d441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling and interpolation based on the column:\n",
    "# groupby NFID:\n",
    "\n",
    "meas_gpy = meas_dfc4.groupby([\"NFID\"])\n",
    "\n",
    "fill_cols = [\"HEIGHT\", \"BP\", \"DIA_BP\", \"PULSE\", \"PATIENT_TYPE\"]\n",
    "inter_cols = [\"FS\", \"PP\", \"A1C\", \"WEIGHT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c55e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad and backfill values that don't need much change:\n",
    "fill_df = meas_gpy.apply(\n",
    "    lambda group: group[fill_cols].interpolate(method=\"pad\").interpolate(method=\"bfill\")\n",
    ")\n",
    "fill_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474b55b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear interpolation for values that change over time:\n",
    "inter_df = meas_gpy.apply(\n",
    "    lambda group: group[inter_cols].interpolate(method=\"linear\", limit_direction=\"both\")\n",
    ")\n",
    "inter_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610f8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_dfc5 = meas_dfc4.copy()\n",
    "meas_dfc5[fill_cols] = fill_df\n",
    "meas_dfc5[inter_cols] = inter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba8ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_dfc5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f521f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI recalculation:\n",
    "meas_dfc5[\"BMI\"] = meas_dfc5[\"WEIGHT\"] * 10000 / meas_dfc5[\"HEIGHT\"].pow(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14df92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_dfc5.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db8a96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Nan values that remain still:\n",
    "\n",
    "# meas_dfc6 = meas_dfc5.dropna(thresh = 2, subset = ['FS', 'PP', 'A1C'])\n",
    "# meas_dfc6.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e5642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Nan values that remain still:\n",
    "\n",
    "meas_dfc6 = meas_dfc5.dropna(\n",
    "    how=\"any\",\n",
    "    subset=[\"FS\", \"PP\", \"A1C\", \"HEIGHT\", \"WEIGHT\", \"BMI\", \"BP\", \"DIA_BP\", \"PULSE\"],\n",
    ")\n",
    "meas_dfc6.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6a73d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Nan values that remain still:\n",
    "\n",
    "# meas_dfc6 = meas_dfc5.dropna(how = 'any')\n",
    "# meas_dfc6.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da26260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_dfc6.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad61891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a cleaned version of the data\n",
    "meas_dfc6.to_csv(\n",
    "    \"../database/interpolated_measurement_details.tsv\", sep=\"\\t\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e50cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Pearson corr of queue len and vf preds: \", metrics_dfc3['vf_preds'].corr(metrics_dfc3['queue_len_total'], method = 'pearson'))\n",
    "meas_dfc6.corr(method=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2661203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# colormap = plt.cm.RdBu\n",
    "# plt.figure(figsize=(15,10))\n",
    "# plt.title(u'Pearsons', y=1.05, size=16)\n",
    "\n",
    "# mask = np.zeros_like(meas_dfc6.corr(method = 'pearson'))\n",
    "# mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# svm = sns.heatmap(meas_dfc6.corr(method = 'pearson'), mask=mask, linewidths=0.1,vmax=1.0,\n",
    "#             square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc088a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_dfc6.corr(method=\"kendall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7749f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_dfc6.corr(method=\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fede8b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean difference between DM and non-DM\n",
    "# cluster among the DM\n",
    "\n",
    "# extact new features? M/F, duration of DM, compliance, lifestyle\n",
    "# what drugs gave good control?\n",
    "# level of compliance based on A1C values come down\n",
    "# A1C < 6.5, 7 good control, Compliance based on subsets of A1C\n",
    "# Based on other factors, Coronary, subset may be relaxed\n",
    "# Medication efficiency?\n",
    "\n",
    "# 20-25 A1C lower\n",
    "# 25-30 A1C higher\n",
    "\n",
    "# take first A1C and correlate with BMI\n",
    "# viz.corr_plot(meas_dfc6, cols = ['HEIGHT', 'WEIGHT', 'BMI', 'BP', 'DIA_BP', 'FS', 'PP', 'PULSE', 'A1C'], color='A1C')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b8209c",
   "metadata": {},
   "source": [
    "## \n",
    "## \n",
    "## A1C scatter plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb6fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots for A1C:\n",
    "\n",
    "meas_gpy = meas_dfc6.groupby([\"NFID\"])\n",
    "\n",
    "a1c_df = pd.DataFrame(columns=[\"max\", \"min\", \"first\", \"last\"])\n",
    "a1c_df[\"max\"] = meas_gpy.A1C.max()\n",
    "a1c_df[\"min\"] = meas_gpy.A1C.min()\n",
    "a1c_df[\"first\"] = meas_gpy.A1C.first()\n",
    "a1c_df[\"last\"] = meas_gpy.A1C.last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e39f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1c_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3de34bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.hist_plot(\n",
    "    a1c_df,\n",
    "    \"first\",\n",
    "    10,\n",
    "    fig_kwargs={\"height\": 500, \"width\": 500, \"title\": \"Histogram of first A1C values\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aa3196",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.hist_plot(\n",
    "    a1c_df,\n",
    "    \"last\",\n",
    "    10,\n",
    "    fig_kwargs={\"height\": 600, \"width\": 500, \"title\": \"Histogram of last A1C values\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402288f9",
   "metadata": {},
   "source": [
    "## \n",
    "## \n",
    "## Clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9b3898",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_df = pd.read_csv(\n",
    "    \"../database/patient_details.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index_col=False,\n",
    "    parse_dates=[\"created_time\"],\n",
    ")\n",
    "pat_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dd9e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f2d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the mean value for each patient (only float columns)\n",
    "meas_dfc7 = meas_dfc6.loc[:, meas_dfc6.columns != \"APPOINT_ID\"].groupby(\"NFID\").mean()\n",
    "# meas_dfc7['PATIENT_TYPE'] = meas_dfc6.groupby('NFID')['PATIENT_TYPE'].first()\n",
    "meas_dfc7.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa49d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_dfc7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3770d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meas_dfc7.index.values\n",
    "pat_dfc = pat_df.loc[pat_df.PATIENT_NFID.isin(meas_dfc7.index.values)].reset_index(\n",
    "    drop=True\n",
    ")\n",
    "pat_dfc = pat_dfc.set_index(\"PATIENT_NFID\")\n",
    "pat_dfc.index.names = [\"NFID\"]\n",
    "pat_dfc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf209f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_dfc.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb2580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ord_enc = OrdinalEncoder()\n",
    "pat_dfc[\"PATIENT_GENDER\"] = ord_enc.fit_transform(pat_dfc[[\"PATIENT_GENDER\"]])\n",
    "\n",
    "# pat_dfc['PATIENT_GENDER'] = pat_dfc['PATIENT_GENDER'].astype('category').cat.codes\n",
    "# pat_dfc['PATIENT_GENDER'].cat.codes\n",
    "pat_dfc[\"DURATION\"] = (\n",
    "    pd.Timestamp.today() - pat_dfc[\"created_time\"]\n",
    ").dt.days  # to get the days they have been diabetic\n",
    "# (pd.Timestamp.today() - pat_dfc['created_time']).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f289fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_dfc7[\"AGE\"] = pat_dfc[\"PATIENT_AGE\"]\n",
    "meas_dfc7[\"GENDER\"] = pat_dfc[\"PATIENT_GENDER\"]\n",
    "meas_dfc7[\"DURATION\"] = pat_dfc[\"DURATION\"]\n",
    "meas_dfc7.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f57ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-MEANS CLUSTERING\n",
    "# Importing Modules\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Convert DataFrame to matrix\n",
    "# df = meas_dfc7.drop(columns=['HEIGHT', 'WEIGHT'])\n",
    "df = meas_dfc7.dropna().copy()\n",
    "df_norm = (df - df.mean()) / df.std()\n",
    "X_scaled = df_norm.values\n",
    "\n",
    "# Using sklearn\n",
    "kmeans = KMeans(n_clusters=3)  # DM and non-DM\n",
    "kmeans.fit(X_scaled)\n",
    "\n",
    "# Get cluster assignment labels\n",
    "labels = kmeans.labels_\n",
    "# Format results as a DataFrame\n",
    "results = pd.DataFrame([meas_dfc6.index, labels]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0710be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e799d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec94f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a number of tests, for 1, 2, ... num_clusters\n",
    "# num_clusters = 30\n",
    "# kmeans_tests = [KMeans(n_clusters=i, init='random', n_init=10) for i in range(1, num_clusters)]\n",
    "# score = [kmeans_tests[i].fit(X_scaled).score(X_scaled) for i in range(len(kmeans_tests))]\n",
    "\n",
    "# fig = plt.figure()\n",
    "\n",
    "# # Plot the curve\n",
    "# plt.plot(range(1, num_clusters),score)\n",
    "# plt.xlabel('Number of Clusters')\n",
    "# plt.ylabel('Score')\n",
    "# plt.title('Elbow Curve')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c6a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a00985",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e69992",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values[:, [3, 4, 6]]\n",
    "\n",
    "y = labels\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "# ax.add_subplot(111, projection='3d')\n",
    "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=y, alpha=0.5)\n",
    "ax.set_title(\"Three clusters trained with k-means\")\n",
    "\n",
    "ax.set_xlabel(\"FS\")\n",
    "ax.set_ylabel(\"PP\")\n",
    "ax.set_zlabel(\"A1C\")\n",
    "# ax.dist = 10\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085264bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for creating a responsive plot\n",
    "%matplotlib widget\n",
    "\n",
    "# importing required libraries\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "X = df.values[:, [3, 4, 6]]\n",
    "\n",
    "y = labels\n",
    "\n",
    "# creating figure\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "# creating the plot\n",
    "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=y, alpha=0.5)\n",
    "\n",
    "# setting title and labels\n",
    "ax.set_title(\"First three PCA directions\")\n",
    "\n",
    "ax.set_xlabel(\"FS\")\n",
    "ax.set_ylabel(\"PP\")\n",
    "ax.set_zlabel(\"A1C\")\n",
    "\n",
    "# displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab70e58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X_scaled)\n",
    "# pca.components_  # we only take the first two features.\n",
    "\n",
    "# Transfor the scaled data to the new PCA space\n",
    "X_reduced = pca.transform(X_scaled)\n",
    "\n",
    "centres_reduced = pca.transform(kmeans.cluster_centers_)\n",
    "\n",
    "# fig = plt.figure()\n",
    "\n",
    "display_factorial_planes(\n",
    "    X_reduced, 2, pca, [(0, 1)], illustrative_var=labels, alpha=0.8\n",
    ")\n",
    "plt.scatter(\n",
    "    centres_reduced[:, 0],\n",
    "    centres_reduced[:, 1],\n",
    "    marker=\"x\",\n",
    "    s=169,\n",
    "    linewidths=3,\n",
    "    color=\"black\",\n",
    "    zorder=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7dcf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame containing our centroids\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_, columns=df.columns)\n",
    "\n",
    "centroids = centroids * df.std() + df.mean()\n",
    "\n",
    "centroids[\"cluster\"] = centroids.index\n",
    "\n",
    "display_parallel_coordinates_centroids(centroids, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88780ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "70db6e888d1dbeb70df6284f3aa7295c3baa07c36893bc9a66337ae1965c9ca1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
